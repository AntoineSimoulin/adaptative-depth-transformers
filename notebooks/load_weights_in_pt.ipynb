{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f67174-4e27-4958-a550-80ebaa0b5573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With ipython notebooks\n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=\"\"\n",
    "\n",
    "# With python\n",
    "# import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = \"0,3\"  # specify which GPU(s) to be used\n",
    "\n",
    "# With bash\n",
    "# export CUDA_DEVICE_ORDER=\"PCI_BUS_ID\"\n",
    "# export CUDA_VISIBLE_DEVICES=\"0,3\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13666a2-0150-41bf-8714-939590988782",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./src/hf/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8ae305-9e93-4de7-a17f-aee1e33da87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPython automatically reload all changed code\n",
    "import torch\n",
    "\n",
    "from modeling_albert_act_tf import TFAlbertActModel\n",
    "from modeling_albert_act import AlbertActModel\n",
    "from configuration_albert_act import AlbertActConfig\n",
    "from transformers import AlbertTokenizer, TFAlbertModel\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from titulus import color, print_\n",
    "import json\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517aa0bf-e920-485b-9800-2ce155d0858c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a564b35-ac1d-4bb2-8197-30696e8ca1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing an ALBERT-xxlarge style configuration\n",
    "# albert_act_configuration = AlbertActConfig()\n",
    "\n",
    "\n",
    "with open('albert_config.json', 'r') as f:\n",
    "  albert_config = json.load(f)\n",
    "\n",
    "albert_act_configuration = AlbertActConfig(attention_probs_dropout_prob= 0,\n",
    "  hidden_act=str(albert_config[\"hidden_act\"]),\n",
    "  hidden_dropout_prob=int(albert_config[\"hidden_dropout_prob\"]),\n",
    "  embedding_size=int(albert_config[\"embedding_size\"]),\n",
    "  hidden_size=int(albert_config[\"hidden_size\"]),\n",
    "  initializer_range=float(albert_config[\"initializer_range\"]),\n",
    "  intermediate_size=int(albert_config[\"intermediate_size\"]),\n",
    "  max_position_embeddings=int(albert_config[\"max_position_embeddings\"]),\n",
    "  num_attention_heads=int(albert_config[\"num_attention_heads\"]),\n",
    "  num_hidden_layers=int(albert_config[\"num_hidden_layers\"]),\n",
    "  net_structure_type=int(albert_config[\"net_structure_type\"]),\n",
    "  gap_size=int(albert_config[\"gap_size\"]),\n",
    "  num_memory_blocks=int(albert_config[\"num_memory_blocks\"]),\n",
    "  inner_group_num=int(albert_config[\"inner_group_num\"]),\n",
    "  down_scale_factor=int(albert_config[\"down_scale_factor\"]),\n",
    "  type_vocab_size=int(albert_config[\"type_vocab_size\"]),\n",
    "  vocab_size=int(albert_config[\"vocab_size\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfe384b-2c2e-400d-90a0-f4624e3dde6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AlbertTokenizer.from_pretrained(\"albert-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e089322-bd88-4ac8-bb23-2a9d0b33b8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AlbertActModel(albert_act_configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf4584c-ca03-4776-8ea6-2fd29f3340ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf9d482-6f6b-4e5b-864b-b3823b397185",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beeeb091-c044-4ce0-af5d-6fda272977e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.input_ids.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92366654-2b8c-4d8f-a5aa-1b02c473fa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09f77bf-b0bd-463a-b7b9-0b9ab0b79ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa3f087-49d6-4077-a3b4-63e984601bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "[n for (n, p) in model.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f3f473-2f46-42f5-9a87-06e76066bcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([n for (n, p) in model.named_parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd913a5-37f6-4459-a50b-58831f954453",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_assignment_map = {\n",
    "  'embeddings.word_embeddings.weight': 'bert-embeddings-word_embeddings.npy',\n",
    "  'embeddings.token_type_embeddings.weight': 'bert-embeddings-token_type_embeddings.npy',\n",
    "  'embeddings.position_embeddings.weight': 'bert-embeddings-position_embeddings.npy',\n",
    "  'embeddings.LayerNorm.weight': 'bert-embeddings-layer_normalization-gamma.npy',\n",
    "  'embeddings.LayerNorm.bias': 'bert-embeddings-layer_normalization-beta.npy',\n",
    "  'encoder.embedding_hidden_mapping_in.weight': 'bert-encoder-embedding_hidden_mapping_in-kernel.npy',\n",
    "  'encoder.embedding_hidden_mapping_in.bias': 'bert-encoder-embedding_hidden_mapping_in-bias.npy',\n",
    "  'encoder.albert_layer.attention.query.weight': 'bert-encoder-transformer-attention_1-self-query-kernel.npy',\n",
    "  'encoder.albert_layer.attention.query.bias': 'bert-encoder-transformer-attention_1-self-query-bias.npy',\n",
    "  'encoder.albert_layer.attention.key.weight': 'bert-encoder-transformer-attention_1-self-key-kernel.npy',\n",
    "  'encoder.albert_layer.attention.key.bias': 'bert-encoder-transformer-attention_1-self-key-bias.npy',\n",
    "  'encoder.albert_layer.attention.value.weight': 'bert-encoder-transformer-attention_1-self-value-kernel.npy',\n",
    "  'encoder.albert_layer.attention.value.bias': 'bert-encoder-transformer-attention_1-self-value-bias.npy',\n",
    "  'encoder.albert_layer.attention.dense.weight': 'bert-encoder-transformer-attention_1-output-dense-kernel.npy',\n",
    "  'encoder.albert_layer.attention.dense.bias': 'bert-encoder-transformer-attention_1-output-dense-bias.npy',\n",
    "  'encoder.albert_layer.act.dense.weight': 'bert-encoder-transformer-halting-dense-kernel.npy',\n",
    "  'encoder.albert_layer.act.dense.bias': 'bert-encoder-transformer-halting-dense-bias.npy',\n",
    "  'encoder.albert_layer.LayerNorm.weight': 'transformer-layer_normalization-gamma.npy',\n",
    "  'encoder.albert_layer.LayerNorm.bias': 'transformer-layer_normalization-beta.npy',\n",
    "  'encoder.albert_layer.ffn.weight': 'bert-encoder-transformer-ffn_1-intermediate-dense-kernel.npy',\n",
    "  'encoder.albert_layer.ffn.bias': 'bert-encoder-transformer-ffn_1-intermediate-dense-bias.npy',\n",
    "  'encoder.albert_layer.ffn_output.weight': 'bert-encoder-transformer-ffn_1-intermediate-output-dense-kernel.npy',\n",
    "  'encoder.albert_layer.ffn_output.bias': 'bert-encoder-transformer-ffn_1-intermediate-output-dense-bias.npy',\n",
    "  'encoder.albert_layer.full_layer_layer_norm.weight': 'transformer-layer_normalization_1-gamma.npy',\n",
    "  'encoder.albert_layer.full_layer_layer_norm.bias': 'transformer-layer_normalization_1-beta.npy',\n",
    "  'pooler.weight': 'bert-pooler-dense-kernel.npy',\n",
    "  'pooler.bias': 'bert-pooler-dense-bias.npy',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be45c0b-ee7a-4b07-975f-c7e4f4ec8f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.embeddings.word_embeddings.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907cd2c8-6888-4a4c-b0bb-032a2273277d",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0219d1-b214-4066-acd0-c8cba8f0a319",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "  # print(name)\n",
    "    \n",
    "  file_name = pt_assignment_map[name]\n",
    "  # print(file_name)\n",
    "\n",
    "  with open(os.path.join('./weights/', file_name), 'rb') as f:\n",
    "    save_param = np.load(f)\n",
    "  if name in ['encoder.albert_layer.act.dense.weight', \n",
    "              'encoder.embedding_hidden_mapping_in.weight', \n",
    "              'albert_layer.act.dense.weight', \n",
    "              'encoder.albert_layer.ffn.weight', \n",
    "              'encoder.albert_layer.ffn_output.weight',\n",
    "             'encoder.albert_layer.attention.query.weight',\n",
    "             'encoder.albert_layer.attention.key.weight',\n",
    "             'encoder.albert_layer.attention.value.weight',\n",
    "             'encoder.albert_layer.attention.dense.weight']:\n",
    "    state_dict[name] = torch.Tensor(save_param).transpose(0, 1)\n",
    "  else:\n",
    "    state_dict[name] = torch.Tensor(save_param)\n",
    "  print(name, state_dict[name].shape)\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c827b757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_pretrained('./albert-act-base/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e247c2f2-19ab-469a-b4e0-31584205c4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AlbertActModel.from_pretrained('./albert-act-base/')\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f57f8e8-74a6-42c7-956d-5a9c7882516f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AlbertTokenizer.from_pretrained(\"./albert-act-base/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ee8a3a-ab9f-405d-9033-12b151ad2770",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"a lump in the middle of the monkeys stirred and then fell quiet .\", return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf42dfe-774d-43cf-801d-72ad027aa983",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c31ebb-f42f-4644-a5a2-be4eb51ad06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(**inputs)\n",
    "outputs.updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e7aee8-00d6-4760-a558-0b8571b8123a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
