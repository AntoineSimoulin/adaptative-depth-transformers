{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "wHQH4OCHZ9bq"
      },
      "outputs": [],
      "source": [
        "# @markdown Copyright 2020 The ALBERT Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkTLZ3I4_7c_"
      },
      "source": [
        "# ALBERT End to End (Fine-tuning + Predicting) with Cloud TPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UIspfMuA13n"
      },
      "source": [
        "## Set up environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gowkk7EFBMsS"
      },
      "outputs": [],
      "source": [
        "%tensorflow_version 1.x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opAIkZxfJhxF"
      },
      "outputs": [],
      "source": [
        "# Clone the source code from GitHub.\n",
        "import sys\n",
        "\n",
        "!test -d albert || git clone https://github.com/google-research/albert albert\n",
        "if not 'albert' in sys.path:\n",
        "  sys.path += ['albert']\n",
        "  \n",
        "!pip install -q sentencepiece\n",
        "\n",
        "# Download glue data.\n",
        "! test -d download_glue_repo || git clone https://gist.github.com/60c2bdb54d156a41194446737ce03e2e.git download_glue_repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "reWI8hCeBOHL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pprint\n",
        "import json\n",
        "import logging\n",
        "import numpy as np\n",
        "import itertools\n",
        "import collections\n",
        "import subprocess\n",
        "\n",
        "from google.colab import auth\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.contrib import (\n",
        "  cluster_resolver as contrib_cluster_resolver,\n",
        "  tpu as contrib_tpu\n",
        ")\n",
        "\n",
        "from albert import (\n",
        "    tokenization,\n",
        "    modeling,\n",
        "    classifier_utils,\n",
        "    fine_tuning_utils,\n",
        "    tags_utils\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "4EaD7x1PBU3u"
      },
      "outputs": [],
      "source": [
        "#@markdown # Configure LOGGING\n",
        "LOGGING_LEVEL = \"DEBUG\" #@param [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"]\n",
        "\n",
        "LOGGING_LEVEL_TO_INT = {\n",
        "    \"DEBUG\": 0,\n",
        "    \"INFO\": 1,\n",
        "    \"WARNING\": 2,\n",
        "    \"ERROR\": 3\n",
        "}\n",
        "LOGGING_VERBOSITY = LOGGING_LEVEL_TO_INT.get(LOGGING_LEVEL, 0)\n",
        "\n",
        "log = logging.getLogger('tensorflow')\n",
        "# log.setLevel(logging.INFO)\n",
        "if LOGGING_LEVEL == \"DEBUG\":\n",
        "  log.setLevel(logging.DEBUG)\n",
        "elif LOGGING_LEVEL == \"INFO\":\n",
        "  log.setLevel(logging.INFO)\n",
        "elif LOGGING_LEVEL == \"WARNING\":\n",
        " log.setLevel(logging.WARNING)\n",
        "elif LOGGING_LEVEL == \"ERROR\":\n",
        "  log.setLevel(logging.ERROR)\n",
        "\n",
        "# create formatter and add it to the handlers\n",
        "formatter = logging.Formatter('%(asctime)s :  %(message)s')\n",
        "sh = logging.StreamHandler()\n",
        "sh.setLevel(logging.INFO)\n",
        "sh.setFormatter(formatter)\n",
        "log.handlers = [sh]\n",
        "\n",
        "# tf.logging.set_verbosity(tf.logging.INFO)\n",
        "if LOGGING_LEVEL == \"DEBUG\":\n",
        "  tf.logging.set_verbosity(tf.logging.DEBUG)\n",
        "elif LOGGING_LEVEL == \"INFO\":\n",
        "  tf.logging.set_verbosity(tf.logging.INFO)\n",
        "elif LOGGING_LEVEL == \"WARNING\":\n",
        " tf.logging.set_verbosity(tf.logging.WARNING)\n",
        "elif LOGGING_LEVEL == \"ERROR\":\n",
        "  tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = str(LOGGING_LEVEL)\n",
        "\n",
        "# configure logging\n",
        "tf.autograph.set_verbosity(LOGGING_VERBOSITY)\n",
        "#   Level | Level for Humans | Level Description\n",
        "#  -------|------------------|------------------------------------\n",
        "#   0     | DEBUG            | [Default] Print all messages\n",
        "#   1     | INFO             | Filter out INFO messages\n",
        "#   2     | WARNING          | Filter out INFO & WARNING messages\n",
        "#   3     | ERROR            | Filter out all messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpieLvrfBQUD",
        "outputId": "da633fd8-dedd-4db5-bc99-c342acbf9dd5"
      },
      "outputs": [],
      "source": [
        "# Set up Colab TPU running environment and verify connection to TPU device\n",
        "\n",
        "# Upload credentials to TPU to access GCS bucket.\n",
        "auth.authenticate_user()\n",
        "\n",
        "if 'COLAB_TPU_ADDR' in os.environ:\n",
        "  log.info(\"Using TPU runtime\")\n",
        "  USE_TPU = True\n",
        "  TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "\n",
        "  with tf.Session(TPU_ADDRESS) as session:\n",
        "    log.info('TPU address is ' + TPU_ADDRESS)\n",
        "    print('TPU devices:')\n",
        "    pprint.pprint(session.list_devices())\n",
        "    # Upload credentials to TPU.\n",
        "    with open('/content/adc.json', 'r') as f:\n",
        "      auth_info = json.load(f)\n",
        "    tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "    \n",
        "else:\n",
        "  log.warning('Not connected to TPU runtime')\n",
        "  USE_TPU = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKUqGz8yCfpT",
        "outputId": "40b13881-2662-4ee7-e38b-581ef7ae2445"
      },
      "outputs": [],
      "source": [
        "#@markdown # GCS and TF hub configuration\n",
        "\n",
        "FROM_TF_HUB = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### GCS model (fill if not FROM_TF_HUB)\n",
        "\n",
        "PROJECT_ID = '' #@param {type:\"string\"}\n",
        "os.environ['GOOGLE_CLOUD_PROJECT'] = PROJECT_ID\n",
        "\n",
        "!gcloud config set project $PROJECT_ID\n",
        "PRETRAINING_DIR = \"\" #@param {type:\"string\"}\n",
        "BUCKET_NAME = \"\" #@param {type:\"string\"}\n",
        "MODEL_NAME = \"\" #@param {type:\"string\"}\n",
        "PHASE = \"1\" #@param [\"1\", \"2\"]\n",
        "\n",
        "BASE_DIR = \"gs://\" + BUCKET_NAME\n",
        "if not BASE_DIR or BASE_DIR == \"gs://\":\n",
        "  log.warning(\"WARNING: BUCKET_NAME is not set. \"\n",
        "              \"You will not be able to train the model.\")\n",
        "else:\n",
        "  BUCKET_PATH = \"gs://{}\".format(BUCKET_NAME)\n",
        "\n",
        "TASK_DATA_DIR = 'glue_data'\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### TF hub model (fill if FROM_TF_HUB)\n",
        "\n",
        "if FROM_TF_HUB:\n",
        "  ALBERT_MODEL_HUB = 'https://tfhub.dev/google/albert_' + ALBERT_MODEL + '/' + VERSION\n",
        "  ALBERT_MODEL = 'base' #@param [\"base\", \"large\", \"xlarge\", \"xxlarge\"]\n",
        "  VERSION = \"3\" #@param [\"1\", \"2\", \"3\"]\n",
        "else:\n",
        "  ALBERT_MODEL_HUB = None\n",
        "  ALBERT_GCS_DIR = \"{}/{}\".format(BUCKET_PATH, MODEL_NAME)\n",
        "  DATA_GCS_DIR = \"{}/{}\".format(BUCKET_PATH, PRETRAINING_DIR)\n",
        "  ALBERT_CONFIG_FILE = os.path.join(ALBERT_GCS_DIR, \"albert_config.json\")\n",
        "\n",
        "if not FROM_TF_HUB and (not BASE_DIR or BASE_DIR == \"gs://\"):\n",
        "  raise ValueError(\"You must configure at least one of\"\n",
        "                   \"`TF_HUB` and `BUCKET_NAME`\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "sq4mS0ZX-iOb"
      },
      "outputs": [],
      "source": [
        "#@markdown # Vocabulary definition\n",
        "VOC_SIZE = 30000 #@param {type: \"integer\"}\n",
        "VOCAB_FILE = \"30k-clean-v2.vocab\" #@param {type:\"string\"}\n",
        "SPM_MODEL_FILE = \"30k-clean-v2.model\" #@param {type:\"string\"}\n",
        "DO_LOWER_CASE = True #@param {type:\"boolean\"}\n",
        "\n",
        "VOCAB_FILE = os.path.join(ALBERT_GCS_DIR, VOCAB_FILE)\n",
        "SPM_MODEL_FILE = os.path.join(ALBERT_GCS_DIR, SPM_MODEL_FILE)\n",
        "if not tf.io.gfile.exists(VOCAB_FILE):\n",
        "   log.warning(\"WARNING: vocab file: {} does not exists. You will not be able to evaluate the model.\".format(VOCAB_FILE))\n",
        "if not tf.io.gfile.exists(SPM_MODEL_FILE):\n",
        "   log.warning(\"WARNING: spm model file: {} does not exists. You will not be able to evaluate the model.\".format(SPM_MODEL_FILE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "viIpvKf0_QOg"
      },
      "outputs": [],
      "source": [
        "#@markdown # Evaluation and optimization parameters\n",
        "\n",
        "# DO_TRAIN = True #@param {type:\"boolean\"}\n",
        "# DO_EVAL = True #@param {type:\"boolean\"}\n",
        "# DO_EVAL_ON_PTB = True #@param {type:\"boolean\"}\n",
        "# DO_PREDICT = True #@param {type:\"boolean\"}\n",
        "# TASK = \"MRPC\" #@param [\"MRPC\", \"MNLI\", \"QNLI\", \"QQP\", \"RTE\", \"SST-2\", \"CoLA\", \"STS-B\", \"WNLI\"]\n",
        "GLUE_DIR = os.path.join(ALBERT_GCS_DIR, 'GLUE')\n",
        "USE_BOS = True #@param {type:\"boolean\"}\n",
        "\n",
        "if not tf.io.gfile.exists(GLUE_DIR):\n",
        "  tf.gfile.MakeDirs(GLUE_DIR)\n",
        "  \n",
        "TAU = 5e-4 #@param {type:\"number\"}\n",
        "NUM_TPU_CORES = 8 #@param {type:\"integer\"}\n",
        "OPTIMIZER = \"lamb\" #@param [\"adamw\", \"lamb\"]\n",
        "EVAL_BATCH_SIZE = 32 #@param {type:\"integer\"}\n",
        "PREDICT_BATCH_SIZE = 32 #@param {type:\"integer\"}\n",
        "MAX_SEQ_LENGTH = 128 #@param {type:\"integer\"}\n",
        "NUM_ACCUMULATION_STEPS =  1#@param {type:\"integer\"}\n",
        "MAX_EPOCHS = 4 #@param {type:\"integer\"}\n",
        "WARMUP_STEPS = 200 #@param {type:\"integer\"}\n",
        "# SAVE_CHECKPOINTS_STEPS = 200 #@param {type:\"integer\"}\n",
        "# ITERATIONS_PER_LOOP = 200 #@param {type:\"integer\"}\n",
        "# ITERATIONS_PER_LOOP = int(min(ITERATIONS_PER_LOOP,\n",
        "#                               SAVE_CHECKPOINTS_STEPS))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwoKBIq6tiQE"
      },
      "outputs": [],
      "source": [
        "#@markdown # Hyper parameters search range\n",
        "\n",
        "TRAIN_BATCH_SIZES = 16, 32 #@param\n",
        "TRAIN_BATCH_SIZES = [int(lr) for lr in TRAIN_BATCH_SIZES]\n",
        "LEARNING_RATES = 5e-5, 3e-5, 2e-5 #@param\n",
        "LEARNING_RATES = [float(lr) for lr in LEARNING_RATES]\n",
        "N_SEEDS = 5 #@param {type:\"integer\"}\n",
        "MULTI_SEEDS_TASKS = \"CoLA, STS-B, RTE, MRPC, SST-2, WNLI\" #@param {type:\"string\"}\n",
        "MULTI_SEED_TASKS = [str(lr).lower().strip() for lr in \n",
        "                      MULTI_SEEDS_TASKS.split(',')]\n",
        "\n",
        "hyper_parameters_gridsearch = {\n",
        "    'learning_rate': LEARNING_RATES,\n",
        "    'batch_size': TRAIN_BATCH_SIZES\n",
        "}\n",
        "\n",
        "hyper_parameters_values = [p for p in itertools.product(*[*hyper_parameters_gridsearch.values()])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "168DLD3z1K3w",
        "outputId": "4df329ce-f5c9-4620-f52a-40d362d36da8"
      },
      "outputs": [],
      "source": [
        "INIT_CHECKPOINT = tf.train.latest_checkpoint(os.path.join(ALBERT_GCS_DIR, \"phase_{}\".format(PHASE)))\n",
        "log.info('***** Model checkpoint: {} *****')\n",
        "log.info(INIT_CHECKPOINT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqgMsfuAMgND",
        "outputId": "4c9131bc-b3ea-499d-c4b4-126fd8c9ed45"
      },
      "outputs": [],
      "source": [
        "# if TASK == 'STS-B':\n",
        "#   TASK = 'STS'\n",
        "# elif TASK == 'SST-2':\n",
        "#   TASK = 'SST'\n",
        "\n",
        "!python download_glue_repo/download_glue_data.py --data_dir=$TASK_DATA_DIR \n",
        "# --tasks=$TASK\n",
        "print('***** Task data directory: {} *****'.format(TASK_DATA_DIR))\n",
        "\n",
        "# if TASK == 'STS':\n",
        "#   TASK = 'STS-B'\n",
        "# elif TASK == 'SST':\n",
        " #  TASK = 'SST-2'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uG8BPSnGqyC",
        "outputId": "19dc9012-7f23-4030-d952-e605dc10a61f"
      },
      "outputs": [],
      "source": [
        "# Config definition\n",
        "\n",
        "processors = {\n",
        "    \"cola\": classifier_utils.ColaProcessor,\n",
        "    \"mnli\": classifier_utils.MnliProcessor,\n",
        "    \"mismnli\": classifier_utils.MisMnliProcessor,\n",
        "    \"mrpc\": classifier_utils.MrpcProcessor,\n",
        "    \"rte\": classifier_utils.RteProcessor,\n",
        "    \"sst-2\": classifier_utils.Sst2Processor,\n",
        "    \"sts-b\": classifier_utils.StsbProcessor,\n",
        "    \"qqp\": classifier_utils.QqpProcessor,\n",
        "    \"qnli\": classifier_utils.QnliProcessor,\n",
        "    \"wnli\": classifier_utils.WnliProcessor,\n",
        "    \"diagnostic\": classifier_utils.AXProcessor,\n",
        "}\n",
        "\n",
        "if not FROM_TF_HUB:\n",
        "  albert_config = modeling.AlbertConfig.from_json_file(ALBERT_CONFIG_FILE)\n",
        "  if MAX_SEQ_LENGTH > albert_config.max_position_embeddings:\n",
        "    raise ValueError(\n",
        "        \"Cannot use sequence length %d because the ALBERT model \"\n",
        "        \"was only trained up to sequence length %d\" %\n",
        "        (MAX_SEQ_LENGTH, albert_config.max_position_embeddings))\n",
        "else:\n",
        "  albert_config = None  # Get the config from TF-Hub.\n",
        "\n",
        "tpu_cluster_resolver = None\n",
        "if USE_TPU and TPU_ADDRESS:\n",
        "  tpu_cluster_resolver = contrib_cluster_resolver.TPUClusterResolver(\n",
        "    TPU_ADDRESS, zone=None, project=PROJECT_ID)\n",
        "      \n",
        "is_per_host = contrib_tpu.InputPipelineConfig.PER_HOST_V2\n",
        "\n",
        "tokenizer = fine_tuning_utils.create_vocab(\n",
        "    vocab_file=VOCAB_FILE,\n",
        "    do_lower_case=DO_LOWER_CASE,\n",
        "    spm_model_file=SPM_MODEL_FILE,\n",
        "    hub_module=ALBERT_MODEL_HUB)\n",
        "\n",
        "# tokenizer = tokenization.FullTokenizer(\n",
        "#       vocab_file=VOCAB_FILE, \n",
        "#       do_lower_case=True,\n",
        "#       spm_model_file=SPM_FILE)\n",
        "\n",
        "tokenizer.tokenize(\"This here's an example of using the ALBERT tokenizer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDi6cUpzKqmS"
      },
      "outputs": [],
      "source": [
        "def train_(estimator, task_name, label_list, max_seq_length, tokenizer, \n",
        "           task_data_dir, output_dir, use_tpu, train_batch_size, train_steps):\n",
        "  \n",
        "  train_examples = processor.get_train_examples(task_data_dir)\n",
        "  train_file = os.path.join(output_dir, task_name + \"_train.tf_record\")\n",
        "  if not tf.gfile.Exists(train_file):\n",
        "    classifier_utils.file_based_convert_examples_to_features(\n",
        "      train_examples, label_list, max_seq_length, tokenizer,\n",
        "      train_file, task_name)\n",
        "  tf.logging.info(\"***** Running training *****\")\n",
        "  tf.logging.info(\"  Num examples = %d\", len(train_examples))\n",
        "  tf.logging.info(\"  Batch size = %d\", train_batch_size)\n",
        "  tf.logging.info(\"  Num steps = %d\", train_steps)\n",
        "\n",
        "  # tags_utils.file_based_input_fn_builder(\n",
        "  train_input_fn = classifier_utils.file_based_input_fn_builder(\n",
        "    input_file=train_file,\n",
        "    seq_length=max_seq_length,\n",
        "    is_training=True,\n",
        "    drop_remainder=True,\n",
        "    task_name=task_name,\n",
        "    use_tpu=use_tpu,\n",
        "    bsz=train_batch_size)\n",
        "\n",
        "  estimator.train(input_fn=train_input_fn, max_steps=train_steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSgY_QWCFRcW"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNDN0I7Xe4xk",
        "outputId": "3b9931d4-62e4-42b5-d181-57971aa5b8fe"
      },
      "outputs": [],
      "source": [
        "for TASK in [\"MRPC\", \"MNLI\", \"QNLI\", \"QQP\", \"RTE\", \"SST-2\", \"CoLA\", \"STS-B\"]:\n",
        "\n",
        "  print(TASK)\n",
        "\n",
        "  if USE_BOS:\n",
        "    OUTPUT_DIR = os.path.join(GLUE_DIR, TASK)\n",
        "  else:\n",
        "    OUTPUT_DIR = os.path.join(GLUE_DIR, TASK, 'SUM')\n",
        "\n",
        "  if not tf.io.gfile.exists(OUTPUT_DIR):\n",
        "    tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "\n",
        "  log.info('***** Model output directory: {} *****'.format(OUTPUT_DIR))\n",
        "\n",
        "  task_name = TASK.lower()\n",
        "  if task_name not in processors:\n",
        "    raise ValueError(\"Task not found: %s\" % (task_name))\n",
        "\n",
        "  processor = processors[task_name](\n",
        "      use_spm=True if SPM_MODEL_FILE else False,\n",
        "      do_lower_case=DO_LOWER_CASE)\n",
        "\n",
        "  if task_name in MULTI_SEED_TASKS:\n",
        "      n_seeds_ = N_SEEDS\n",
        "  else:\n",
        "      n_seeds_ = 1\n",
        "\n",
        "  label_list = processor.get_labels()\n",
        "  train_examples = processor.get_train_examples(TASK_DATA_DIR)\n",
        "  n_train_examples = len(train_examples)\n",
        "\n",
        "  for hyperparameters in hyper_parameters_values:\n",
        "    for seed in range(n_seeds_):\n",
        "\n",
        "      learning_rate, train_batch_size = hyperparameters\n",
        "      if task_name in ['mismnli', \"diagnostic\"]:\n",
        "        run_output_dir = os.path.join(os.path.join(GLUE_DIR, 'MNLI'), \n",
        "            str(learning_rate), str(train_batch_size), str(seed))\n",
        "      else:\n",
        "        run_output_dir = os.path.join(\n",
        "            OUTPUT_DIR, str(learning_rate), str(train_batch_size), str(seed))\n",
        "      print(run_output_dir)\n",
        "\n",
        "      n_iterations_per_epoch = int(n_train_examples / train_batch_size)\n",
        "      num_train_steps = int(MAX_EPOCHS * n_iterations_per_epoch)\n",
        "      SAVE_CHECKPOINTS_STEPS = int(n_iterations_per_epoch)\n",
        "      ITERATIONS_PER_LOOP = int(n_iterations_per_epoch)\n",
        "\n",
        "      if not tf.io.gfile.exists(run_output_dir):\n",
        "        # Creates a directory and all parent/intermediate directories.\n",
        "        tf.gfile.MakeDirs(run_output_dir)\n",
        "\n",
        "      run_config = contrib_tpu.RunConfig(\n",
        "        # cluster=tpu_cluster_resolver,\n",
        "        master=TPU_ADDRESS,\n",
        "        model_dir=run_output_dir,\n",
        "        save_checkpoints_steps=int(SAVE_CHECKPOINTS_STEPS),\n",
        "        keep_checkpoint_max=0,\n",
        "        tpu_config=contrib_tpu.TPUConfig(\n",
        "          iterations_per_loop=ITERATIONS_PER_LOOP,\n",
        "          num_shards=NUM_TPU_CORES,\n",
        "          per_host_input_for_training=is_per_host))\n",
        "\n",
        "      # model_fn = tags_utils.model_fn_builder(\n",
        "      model_fn = classifier_utils.model_fn_builder(\n",
        "        albert_config=albert_config,\n",
        "        num_labels=len(label_list),\n",
        "        init_checkpoint=INIT_CHECKPOINT,\n",
        "        learning_rate=learning_rate,\n",
        "        num_train_steps=num_train_steps,\n",
        "        num_warmup_steps=WARMUP_STEPS,\n",
        "        use_tpu=USE_TPU,\n",
        "        use_one_hot_embeddings=USE_TPU,\n",
        "        task_name=task_name,\n",
        "        hub_module=ALBERT_MODEL_HUB,\n",
        "        optimizer=OPTIMIZER,)\n",
        "        # tau=TAU,\n",
        "        # use_bos=USE_BOS)\n",
        "\n",
        "      # If TPU is not available, this will fall back to Estimator on CPU or GPU.\n",
        "      estimator = contrib_tpu.TPUEstimator(\n",
        "        use_tpu=USE_TPU,\n",
        "        model_fn=model_fn,\n",
        "        config=run_config,\n",
        "        train_batch_size=train_batch_size,\n",
        "        eval_batch_size=EVAL_BATCH_SIZE,\n",
        "        export_to_tpu=False)\n",
        "      \n",
        "      if not task_name in ['mismnli', \"diagnostic\"]:\n",
        "        train_(\n",
        "            estimator, \n",
        "            task_name,\n",
        "            label_list, \n",
        "            MAX_SEQ_LENGTH, \n",
        "            tokenizer, \n",
        "            TASK_DATA_DIR, \n",
        "            run_output_dir, \n",
        "            USE_TPU, \n",
        "            train_batch_size, \n",
        "            num_train_steps)\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mV8L8V12Gkr9"
      },
      "source": [
        "## Eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RlHLIJpCaQT"
      },
      "outputs": [],
      "source": [
        "Runs = collections.namedtuple('Runs', 'task, learning_rate batch_size seed epoch ckpt_path')\n",
        "\n",
        "def _find_valid_cands(filenames):\n",
        "  candidates = []\n",
        "  for filename in filenames:\n",
        "    if filename.endswith(\".index\"):\n",
        "      ckpt_name = filename[:-6]\n",
        "      idx = int(ckpt_name.split(\"-\")[-1])\n",
        "      candidates.append((idx, filename))\n",
        "  candidates.sort(key=lambda t: t[0]) \n",
        "  return candidates\n",
        "\n",
        "def _find_runs(output_dir, task_name, stop_ckpt=None):\n",
        "  runs = []\n",
        "  for dir, subdirs, files in tf.io.gfile.walk(output_dir):\n",
        "    if len(subdirs) == 0:\n",
        "      candidates = _find_valid_cands(files)\n",
        "      for epoch, (step, cand) in enumerate(candidates):\n",
        "        if epoch >= 2:\n",
        "          if stop_ckpt is not None:\n",
        "            if not os.path.join(dir, cand) in stop_ckpt:\n",
        "              lr, bsz, seed = dir.split('/')[-4:-1]\n",
        "              runs.append(Runs(task_name, float(lr), int(bsz), int(seed), int(epoch), os.path.join(dir, cand)))\n",
        "          else:\n",
        "            lr, bsz, seed = dir.split('/')[-4:-1]\n",
        "            runs.append(Runs(task_name, float(lr), int(bsz), int(seed), int(epoch), os.path.join(dir, cand)))\n",
        "  return runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udN7oIp-BE2m"
      },
      "outputs": [],
      "source": [
        "def get_eval_results(output_eval_file, task_name):\n",
        "  bashCommand = \"gsutil cp {} eval_results_{}.txt\".format(output_eval_file, task_name)\n",
        "  process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
        "  output, error = process.communicate()\n",
        "  if not tf.io.gfile.exists(\"eval_results_{}.txt\".format(task_name)):\n",
        "    return []\n",
        "  eval_results = []\n",
        "  with open(\"eval_results_{}.txt\".format(task_name), 'r') as f:\n",
        "    eval_results = f.readlines()\n",
        "  eval_results = [e.strip() for e in eval_results]\n",
        "  return eval_results\n",
        "\n",
        "def get_already_eval_ckpt(eval_results):\n",
        "  already_eval_ckpt = []\n",
        "  for run in eval_results:\n",
        "    task, lr, bsz, epoch, seed, ckpt_path, dev_results = run.split('\\t')\n",
        "    already_eval_ckpt.append(ckpt_path)\n",
        "  return already_eval_ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJ65AIoSoAc7"
      },
      "outputs": [],
      "source": [
        "def eval_(estimator, task_name, label_list, max_seq_length, tokenizer, \n",
        "           task_data_dir, output_dir, use_tpu, eval_batch_size, checkpoint_path):\n",
        "\n",
        "  eval_examples = processor.get_dev_examples(task_data_dir)\n",
        "  num_actual_eval_examples = len(eval_examples)\n",
        "  if use_tpu:\n",
        "    # TPU requires a fixed batch size for all batches, therefore the number\n",
        "    # of examples must be a multiple of the batch size, or else examples\n",
        "    # will get dropped. So we pad with fake examples which are ignored\n",
        "    # later on. These do NOT count towards the metric (all tf.metrics\n",
        "    # support a per-instance weight, and these get a weight of 0.0).\n",
        "    while len(eval_examples) % eval_batch_size != 0:\n",
        "      eval_examples.append(classifier_utils.PaddingInputExample())\n",
        "\n",
        "  eval_file = os.path.join(output_dir, task_name + \"_eval.tf_record\")\n",
        "  if not tf.gfile.Exists(eval_file):\n",
        "    classifier_utils.file_based_convert_examples_to_features(\n",
        "        eval_examples, label_list, max_seq_length, tokenizer,\n",
        "        eval_file, task_name)\n",
        "\n",
        "  tf.logging.info(\"***** Running evaluation *****\")\n",
        "  tf.logging.info(\"  Num examples = %d (%d actual, %d padding)\",\n",
        "                  len(eval_examples), num_actual_eval_examples,\n",
        "                  len(eval_examples) - num_actual_eval_examples)\n",
        "  tf.logging.info(\"  Batch size = %d\", eval_batch_size)\n",
        "\n",
        "  # This tells the estimator to run through the entire set.\n",
        "  eval_steps = None\n",
        "  # However, if running eval on the TPU, you will need to specify the\n",
        "  # number of steps.\n",
        "  if use_tpu:\n",
        "    assert len(eval_examples) % eval_batch_size == 0\n",
        "    eval_steps = int(len(eval_examples) // eval_batch_size)\n",
        "\n",
        "  eval_drop_remainder = True if use_tpu else False\n",
        "  # tags_utils\n",
        "  eval_input_fn = classifier_utils.file_based_input_fn_builder(\n",
        "      input_file=eval_file,\n",
        "      seq_length=max_seq_length,\n",
        "      is_training=False,\n",
        "      drop_remainder=eval_drop_remainder,\n",
        "      task_name=task_name,\n",
        "      use_tpu=use_tpu,\n",
        "      bsz=eval_batch_size)\n",
        "  \n",
        "  result = estimator.evaluate(\n",
        "          input_fn=eval_input_fn,\n",
        "          steps=eval_steps,\n",
        "          checkpoint_path=checkpoint_path)\n",
        "  global_step = result[\"global_step\"]\n",
        "  tf.logging.info(\"***** Eval results *****\")\n",
        "  for key in sorted(result.keys()):\n",
        "    tf.logging.info(\"  %s = %s\", key, str(result[key]))\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxaxzDyWe4zy",
        "outputId": "f3cc328a-567c-40de-9537-5dc661e3e067"
      },
      "outputs": [],
      "source": [
        "for TASK in [\"MRPC\", \"MNLI\", \"MISMNLI\", \"QNLI\", \"QQP\", \"RTE\", \"SST-2\", \"CoLA\", \"STS-B\"]:\n",
        "\n",
        "  print(TASK)\n",
        "\n",
        "  try:\n",
        "    writer.close()\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  if USE_BOS:\n",
        "    OUTPUT_DIR = os.path.join(GLUE_DIR, TASK)\n",
        "  else:\n",
        "    OUTPUT_DIR = os.path.join(GLUE_DIR, TASK, 'SUM')\n",
        "\n",
        "  if not tf.io.gfile.exists(OUTPUT_DIR):\n",
        "    tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "\n",
        "  output_eval_file = os.path.join(OUTPUT_DIR, \"eval_results.txt\")\n",
        "  writer = tf.gfile.GFile(output_eval_file, \"w\")\n",
        "\n",
        "  task_name = TASK.lower()\n",
        "  if task_name not in processors:\n",
        "    raise ValueError(\"Task not found: %s\" % (task_name))\n",
        "\n",
        "  processor = processors[task_name](\n",
        "      use_spm=True if SPM_MODEL_FILE else False,\n",
        "      do_lower_case=DO_LOWER_CASE)\n",
        "\n",
        "  label_list = processor.get_labels()\n",
        "  if task_name in ['mismnli', \"diagnostic\"]:\n",
        "    run_output_dir = os.path.join(os.path.join(GLUE_DIR, 'MNLI'))\n",
        "  else:\n",
        "    run_output_dir = os.path.join(os.path.join(GLUE_DIR, TASK))\n",
        "  print(run_output_dir)\n",
        "\n",
        "  runs = _find_runs(run_output_dir, task_name)\n",
        "  tf.logging.info(\" found %i runs.\", len(runs))\n",
        "\n",
        "  eval_results = get_eval_results(output_eval_file, task_name)\n",
        "  print(eval_results)\n",
        "\n",
        "  already_eval_ckpt = get_already_eval_ckpt(eval_results)\n",
        "  print(already_eval_ckpt)\n",
        "\n",
        "  runs = [run for run in runs if not run.ckpt_path in already_eval_ckpt]\n",
        "\n",
        "  for run in runs:\n",
        "    print(run)\n",
        "    tf.logging.info(\"Eval {}.\".format(run))\n",
        "\n",
        "    run_config = contrib_tpu.RunConfig(\n",
        "      master=TPU_ADDRESS,\n",
        "      # model_dir=run_output_dir,\n",
        "      tpu_config=contrib_tpu.TPUConfig(\n",
        "        iterations_per_loop=1000,\n",
        "        num_shards=NUM_TPU_CORES,\n",
        "        per_host_input_for_training=is_per_host))\n",
        "\n",
        "    # tags_utils\n",
        "    model_fn = classifier_utils.model_fn_builder(\n",
        "      albert_config=albert_config,\n",
        "      num_labels=len(label_list),\n",
        "      init_checkpoint=run.ckpt_path[:-6],\n",
        "      learning_rate=run.learning_rate,\n",
        "      num_train_steps=1000,\n",
        "      num_warmup_steps=1000,\n",
        "      use_tpu=USE_TPU,\n",
        "      use_one_hot_embeddings=USE_TPU,\n",
        "      task_name=task_name,\n",
        "      hub_module=ALBERT_MODEL_HUB,\n",
        "      optimizer=OPTIMIZER,)\n",
        "      # tau=TAU,\n",
        "      # use_bos=USE_BOS)\n",
        "\n",
        "    estimator = contrib_tpu.TPUEstimator(\n",
        "      use_tpu=USE_TPU,\n",
        "      model_fn=model_fn,\n",
        "      config=run_config,\n",
        "      train_batch_size=run.batch_size,\n",
        "      eval_batch_size=EVAL_BATCH_SIZE,\n",
        "      export_to_tpu=False)\n",
        "\n",
        "    dev_results = eval_(\n",
        "        estimator, \n",
        "        task_name, \n",
        "        label_list, \n",
        "        MAX_SEQ_LENGTH, \n",
        "        tokenizer, \n",
        "        TASK_DATA_DIR, \n",
        "        OUTPUT_DIR, \n",
        "        USE_TPU, \n",
        "        EVAL_BATCH_SIZE,\n",
        "        run.ckpt_path[:-6])\n",
        "    \n",
        "    if task_name == \"sts-b\":\n",
        "      key_name = \"pearson\"\n",
        "    elif task_name == \"cola\":\n",
        "      key_name = \"matthew_corr\"\n",
        "    else:\n",
        "      key_name = \"eval_accuracy\"\n",
        "\n",
        "    for key in sorted(dev_results.keys()):\n",
        "      tf.logging.info(\"  %s = %s\", key, str(dev_results[key]))\n",
        "    tf.logging.info(\"{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n\".format(\n",
        "        task_name, run.learning_rate, run.batch_size, run.epoch, run.seed, run.ckpt_path, dev_results[key_name]))\n",
        "    writer.write(\"{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n\".format(\n",
        "        task_name, run.learning_rate, run.batch_size, run.epoch, run.seed, run.ckpt_path, dev_results[key_name]))\n",
        "    writer.flush()\n",
        "\n",
        "  writer.close()    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvGn510qJiZz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IR66fBY_JicT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxzHdewtJieh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2EAwrwaJigQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6oRM31P_JiiV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3k9ZUR4JikE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCC9Ep5oGUnS"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  writer.close()\n",
        "except:\n",
        "  pass\n",
        "\n",
        "  \n",
        "output_eval_file = os.path.join(OUTPUT_DIR, \"eval_results.txt\")\n",
        "writer = tf.gfile.GFile(output_eval_file, \"w\")\n",
        "\n",
        "for hyperparameters in hyper_parameters_values:\n",
        "  for seed in range(n_seeds_):\n",
        "\n",
        "    learning_rate, train_batch_size = hyperparameters\n",
        "    if not task_name in ['rte', 'mismnli']:\n",
        "      run_output_dir = os.path.join(os.path.join(GLUE_DIR, 'mnli'), \n",
        "          str(learning_rate), str(train_batch_size), str(seed))\n",
        "    else:\n",
        "      run_output_dir = os.path.join(\n",
        "          OUTPUT_DIR, str(learning_rate), str(train_batch_size), str(seed))\n",
        "    print(run_output_dir)\n",
        "\n",
        "    n_iterations_per_epoch = int(n_train_examples / train_batch_size)\n",
        "    num_train_steps = int(MAX_EPOCHS * n_iterations_per_epoch)\n",
        "    SAVE_CHECKPOINTS_STEPS = int(n_iterations_per_epoch)\n",
        "    ITERATIONS_PER_LOOP = int(n_iterations_per_epoch)\n",
        "\n",
        "    if not tf.io.gfile.exists(run_output_dir):\n",
        "      # Creates a directory and all parent/intermediate directories.\n",
        "      tf.gfile.MakeDirs(run_output_dir)\n",
        "\n",
        "    run_config = contrib_tpu.RunConfig(\n",
        "      # cluster=tpu_cluster_resolver,\n",
        "      master=TPU_ADDRESS,\n",
        "      model_dir=run_output_dir,\n",
        "      save_checkpoints_steps=int(SAVE_CHECKPOINTS_STEPS),\n",
        "      keep_checkpoint_max=0,\n",
        "      tpu_config=contrib_tpu.TPUConfig(\n",
        "        iterations_per_loop=ITERATIONS_PER_LOOP,\n",
        "        num_shards=NUM_TPU_CORES,\n",
        "        per_host_input_for_training=is_per_host))\n",
        "\n",
        "    model_fn = tags_utils.model_fn_builder(\n",
        "      albert_config=albert_config,\n",
        "      num_labels=len(label_list),\n",
        "      init_checkpoint=INIT_CHECKPOINT,\n",
        "      learning_rate=learning_rate,\n",
        "      num_train_steps=num_train_steps,\n",
        "      num_warmup_steps=WARMUP_STEPS,\n",
        "      use_tpu=USE_TPU,\n",
        "      use_one_hot_embeddings=USE_TPU,\n",
        "      task_name=task_name,\n",
        "      hub_module=ALBERT_MODEL_HUB,\n",
        "      optimizer=OPTIMIZER,\n",
        "      tau=TAU,\n",
        "      use_bos=USE_BOS)\n",
        "\n",
        "    # If TPU is not available, this will fall back to Estimator on CPU or GPU.\n",
        "    estimator = contrib_tpu.TPUEstimator(\n",
        "      use_tpu=USE_TPU,\n",
        "      model_fn=model_fn,\n",
        "      config=run_config,\n",
        "      train_batch_size=train_batch_size,\n",
        "      eval_batch_size=EVAL_BATCH_SIZE,\n",
        "      export_to_tpu=False)\n",
        "    \n",
        "    if not task_name in ['rte', 'mismnli']:\n",
        "      train_(\n",
        "          estimator, \n",
        "          task_name,\n",
        "          label_list, \n",
        "          MAX_SEQ_LENGTH, \n",
        "          tokenizer, \n",
        "          TASK_DATA_DIR, \n",
        "          run_output_dir, \n",
        "          USE_TPU, \n",
        "          train_batch_size, \n",
        "          num_train_steps)\n",
        "    \n",
        "    if not task_name in ['rte']:\n",
        "      runs = _find_runs(run_output_dir, task_name)\n",
        "      tf.logging.info(\" found %i runs.\", len(runs))\n",
        "      for run in runs:\n",
        "        print(run)\n",
        "        tf.logging.info(\"Eval {}.\".format(run))\n",
        "\n",
        "        dev_results = eval_(\n",
        "            estimator, \n",
        "            task_name, \n",
        "            label_list, \n",
        "            MAX_SEQ_LENGTH, \n",
        "            tokenizer, \n",
        "            TASK_DATA_DIR, \n",
        "            OUTPUT_DIR, \n",
        "            USE_TPU, \n",
        "            EVAL_BATCH_SIZE,\n",
        "            run.ckpt_path[:-6])\n",
        "    \n",
        "        if task_name == \"sts-b\":\n",
        "          key_name = \"pearson\"\n",
        "        elif task_name == \"cola\":\n",
        "          key_name = \"matthew_corr\"\n",
        "        else:\n",
        "          key_name = \"eval_accuracy\"\n",
        "\n",
        "        for key in sorted(dev_results.keys()):\n",
        "          tf.logging.info(\"  %s = %s\", key, str(dev_results[key]))\n",
        "          # writer.write(\"%s = %s\\n\" % (key, str(dev_results[key])))\n",
        "        tf.logging.info(\"{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n\".format(\n",
        "            task_name, run.learning_rate, run.batch_size, run.epoch, run.seed, run.ckpt_path, dev_results[key_name]))\n",
        "        writer.write(\"{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n\".format(\n",
        "            task_name, run.learning_rate, run.batch_size, run.epoch, run.seed, run.ckpt_path, dev_results[key_name]))\n",
        "        writer.flush()\n",
        "\n",
        "writer.close()    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0i0WyyKJGlqp"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfj7J1r-ED3P"
      },
      "outputs": [],
      "source": [
        "def eval_results_to_dict(eval_results, task_name):\n",
        "  eval_results_dict = {}\n",
        "  for run in eval_results:\n",
        "    task, lr, bsz, epoch, seed, ckpt_path, dev_results = run.split('\\t')\n",
        "    if task_name == task:\n",
        "      key = \"{}_{}_{}\".format(lr, bsz, epoch)\n",
        "      if key in eval_results_dict:\n",
        "        eval_results_dict[key] = eval_results_dict[key] + [float(dev_results)]\n",
        "      else:\n",
        "        eval_results_dict[key] = [float(dev_results)]\n",
        "  return eval_results_dict\n",
        "\n",
        "def get_best_hp(eval_results, task_name):\n",
        "  eval_results_dict = eval_results_to_dict(eval_results, task_name)\n",
        "  best_dev_result = -1\n",
        "  best_dev_key = ''\n",
        "  for (k, v) in eval_results_dict.items():\n",
        "    eval_results_dict[k] = np.mean(v)\n",
        "    if eval_results_dict[k] > best_dev_result:\n",
        "      best_dev_result = eval_results_dict[k]\n",
        "      best_dev_key = k\n",
        "  return best_dev_result, best_dev_key\n",
        "\n",
        "def get_best_ckpt(eval_results, best_dev_key, task_name):\n",
        "  best_dev_result_all = -1\n",
        "  best_dev_result_all_ckpt = \"\"\n",
        "  for run in eval_results:\n",
        "    task, lr, bsz, epoch, seed, ckpt_path, dev_results = run.split('\\t')\n",
        "    if task_name == task:\n",
        "      key = \"{}_{}_{}\".format(lr, bsz, epoch)\n",
        "      if best_dev_key == key:\n",
        "        if float(dev_results) > best_dev_result_all:\n",
        "          best_dev_result_all_ckpt = ckpt_path\n",
        "          best_dev_result_all = float(dev_results)\n",
        "  return best_dev_result_all, best_dev_result_all_ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_67rOt5Ginw"
      },
      "outputs": [],
      "source": [
        "def predict_(task_name, label_list, max_seq_length, tokenizer, \n",
        "             task_data_dir, output_dir, use_tpu, predict_batch_size,\n",
        "             checkpoint_path):\n",
        "\n",
        "  predict_examples = processor.get_test_examples(TASK_DATA_DIR)\n",
        "  \n",
        "  num_actual_predict_examples = len(predict_examples)\n",
        "  if USE_TPU:\n",
        "    # TPU requires a fixed batch size for all batches, therefore the number\n",
        "    # of examples must be a multiple of the batch size, or else examples\n",
        "    # will get dropped. So we pad with fake examples which are ignored\n",
        "    # later on.\n",
        "    while len(predict_examples) % predict_batch_size != 0:\n",
        "      predict_examples.append(classifier_utils.PaddingInputExample())\n",
        "\n",
        "  predict_file = os.path.join(OUTPUT_DIR, \"predict.tf_record\")\n",
        "  classifier_utils.file_based_convert_examples_to_features(\n",
        "      predict_examples, label_list,\n",
        "      max_seq_length, tokenizer,\n",
        "      predict_file, task_name)\n",
        "\n",
        "  tf.logging.info(\"***** Running prediction*****\")\n",
        "  tf.logging.info(\"  Num examples = %d (%d actual, %d padding)\",\n",
        "                  len(predict_examples), num_actual_predict_examples,\n",
        "                  len(predict_examples) - num_actual_predict_examples)\n",
        "  tf.logging.info(\"  Batch size = %d\", predict_batch_size)\n",
        "\n",
        "  predict_drop_remainder = True if use_tpu else False\n",
        "  # tags_utils\n",
        "  predict_input_fn = classifier_utils.file_based_input_fn_builder(\n",
        "    input_file=predict_file,\n",
        "    seq_length=max_seq_length,\n",
        "    is_training=False,\n",
        "    drop_remainder=predict_drop_remainder,\n",
        "    task_name=task_name,\n",
        "    use_tpu=use_tpu,\n",
        "    bsz=predict_batch_size)\n",
        "  \n",
        "  run_config = contrib_tpu.RunConfig(\n",
        "    master=TPU_ADDRESS,\n",
        "    # model_dir=run_output_dir,\n",
        "    tpu_config=contrib_tpu.TPUConfig(\n",
        "      iterations_per_loop=1000,\n",
        "      num_shards=NUM_TPU_CORES,\n",
        "      per_host_input_for_training=is_per_host))\n",
        "\n",
        "  tags_utils\n",
        "  model_fn = classifier_utils.model_fn_builder(\n",
        "    albert_config=albert_config,\n",
        "    num_labels=len(label_list),\n",
        "    init_checkpoint=checkpoint_path[:-6],\n",
        "    learning_rate=float(best_dev_result_all_ckpt.split('/')[-4]),\n",
        "    num_train_steps=1000,\n",
        "    num_warmup_steps=1000,\n",
        "    use_tpu=use_tpu,\n",
        "    use_one_hot_embeddings=use_tpu,\n",
        "    task_name=task_name,\n",
        "    hub_module=ALBERT_MODEL_HUB,\n",
        "    optimizer=OPTIMIZER,)\n",
        "    # tau=TAU,\n",
        "    # use_bos=USE_BOS)\n",
        "\n",
        "  estimator = contrib_tpu.TPUEstimator(\n",
        "    use_tpu=use_tpu,\n",
        "    model_fn=model_fn,\n",
        "    config=run_config,\n",
        "    train_batch_size=int(best_dev_result_all_ckpt.split('/')[-3]),\n",
        "    predict_batch_size=int(best_dev_result_all_ckpt.split('/')[-3]),\n",
        "    export_to_tpu=False)\n",
        "\n",
        "  result = estimator.predict(\n",
        "    input_fn=predict_input_fn,\n",
        "    checkpoint_path=checkpoint_path[:-6])\n",
        "  \n",
        "  return list(result)\n",
        "\n",
        "\n",
        "def write_prediction_file(output_predict_file, output_submit_file, result):\n",
        "  predict_examples = processor.get_test_examples(TASK_DATA_DIR)\n",
        "  num_actual_predict_examples = len(predict_examples)\n",
        "  with tf.gfile.GFile(output_predict_file, \"w\") as pred_writer,\\\n",
        "      tf.gfile.GFile(output_submit_file, \"w\") as sub_writer:\n",
        "    sub_writer.write(\"index\" + \"\\t\" + \"prediction\\n\")\n",
        "    num_written_lines = 0\n",
        "    tf.logging.info(\"***** Predict results *****\")\n",
        "    for (i, (example, prediction)) in\\\n",
        "      enumerate(zip(predict_examples, result)):\n",
        "      probabilities = prediction[\"probabilities\"]\n",
        "      if i >= num_actual_predict_examples:\n",
        "        break\n",
        "    \n",
        "      output_line = \"\\t\".join(\n",
        "          str(class_probability)\n",
        "          for class_probability in probabilities) + \"\\n\"\n",
        "      pred_writer.write(output_line)\n",
        "\n",
        "      if task_name != \"sts-b\":\n",
        "        actual_label = label_list[int(prediction[\"predictions\"])]\n",
        "      else:\n",
        "        actual_label = str(max(min(prediction[\"predictions\"], 5.0), 0.0))\n",
        "      sub_writer.write(example.guid + \"\\t\" + actual_label + \"\\n\")\n",
        "      num_written_lines += 1\n",
        "  assert num_written_lines == num_actual_predict_examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VA2vqCZO3E96",
        "outputId": "99a2768d-562a-4452-daa3-c7e40c3e349e"
      },
      "outputs": [],
      "source": [
        "for TASK in [\"MRPC\", \"MNLI\", \"MISMNLI\", \"QNLI\", \"QQP\", \"RTE\", \"SST-2\", \"CoLA\", \"STS-B\", \"diagnostic\", \"WNLI\"]:  # \"MRPC\", \"MNLI\", \"MISMNLI\", \"QNLI\", \"QQP\", \"RTE\", \"SST-2\", \"CoLA\", \"STS-B\", \"diagnostic\", \"WNLI\"\n",
        "\n",
        "  print(TASK)\n",
        "\n",
        "  if USE_BOS:\n",
        "    OUTPUT_DIR = os.path.join(GLUE_DIR, TASK)\n",
        "  else:\n",
        "    OUTPUT_DIR = os.path.join(GLUE_DIR, TASK, 'SUM')\n",
        "\n",
        "  if not tf.io.gfile.exists(OUTPUT_DIR):\n",
        "    tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "\n",
        "  if task_name in [\"diagnostic\"]:\n",
        "    output_eval_file = os.path.join(GLUE_DIR, 'MNLI', \"eval_results.txt\")\n",
        "  else:\n",
        "    output_eval_file = os.path.join(OUTPUT_DIR, \"eval_results.txt\")\n",
        "  print(output_eval_file)  \n",
        "\n",
        "  task_name = TASK.lower()\n",
        "  if task_name not in processors:\n",
        "    raise ValueError(\"Task not found: %s\" % (task_name))\n",
        "\n",
        "  processor = processors[task_name](\n",
        "      use_spm=True if SPM_MODEL_FILE else False,\n",
        "      do_lower_case=DO_LOWER_CASE)\n",
        "\n",
        "  label_list = processor.get_labels()\n",
        "\n",
        "  TASK_SAVE_NAME = \"\"\n",
        "  if TASK == \"MNLI\":\n",
        "    TASK_SAVE_NAME = \"MNLI-m\"\n",
        "  elif TASK == \"MISMNLI\":\n",
        "    TASK_SAVE_NAME = \"MNLI-mm\"\n",
        "  elif TASK == \"diagnostic\":\n",
        "    TASK_SAVE_NAME = \"AX\"\n",
        "\n",
        "  if TASK == \"WNLI\":\n",
        "    # Always predict majority class\n",
        "    results = [{\"probabilities\": [1., 0.], \"predictions\": 0} for _ in range(146)]\n",
        "    output_predict_file = os.path.join(OUTPUT_DIR, \"test_results.tsv\")\n",
        "    if not tf.io.gfile.exists(os.path.join(GLUE_DIR, 'submission')):\n",
        "      tf.gfile.MakeDirs(os.path.join(GLUE_DIR, 'submission'))\n",
        "    output_submit_file = os.path.join(GLUE_DIR, 'submission', \"{}.tsv\".format(TASK if not TASK_SAVE_NAME else TASK_SAVE_NAME))\n",
        "    print(output_submit_file)\n",
        "    write_prediction_file(output_predict_file, output_submit_file, results)\n",
        "    continue\n",
        "\n",
        "  eval_results = get_eval_results(output_eval_file, task_name if task_name not in [\"diagnostic\"] else \"mnli\")\n",
        "  print(eval_results)\n",
        "\n",
        "  best_dev_result, best_dev_key = get_best_hp(eval_results, task_name if task_name not in [\"diagnostic\"] else \"mnli\")\n",
        "  print(best_dev_result, best_dev_key)\n",
        "\n",
        "  best_dev_result_all, best_dev_result_all_ckpt = get_best_ckpt(eval_results, best_dev_key, task_name if task_name not in [\"diagnostic\"] else \"mnli\")\n",
        "  print(best_dev_result_all, best_dev_result_all_ckpt)\n",
        "\n",
        "  results = predict_(task_name, \n",
        "                     label_list, \n",
        "                     MAX_SEQ_LENGTH, \n",
        "                     tokenizer, \n",
        "                     TASK_DATA_DIR, \n",
        "                     OUTPUT_DIR, \n",
        "                     USE_TPU, \n",
        "                     PREDICT_BATCH_SIZE,\n",
        "                     best_dev_result_all_ckpt)\n",
        "   \n",
        "  output_predict_file = os.path.join(OUTPUT_DIR, \"test_results.tsv\")\n",
        "  if not tf.io.gfile.exists(os.path.join(GLUE_DIR, 'submission')):\n",
        "    tf.gfile.MakeDirs(os.path.join(GLUE_DIR, 'submission'))\n",
        "\n",
        "  output_submit_file = os.path.join(GLUE_DIR, 'submission', \"{}.tsv\".format(TASK if not TASK_SAVE_NAME else TASK_SAVE_NAME))\n",
        "  write_prediction_file(output_predict_file, output_submit_file, results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bb0ah7QVO-jM"
      },
      "outputs": [],
      "source": [
        "!mkdir submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWvnf0CNei67",
        "outputId": "c96f68c4-b50f-4aa9-f7aa-6a4bbfd9bb89"
      },
      "outputs": [],
      "source": [
        "!gsutil -m cp \\\n",
        "  \"gs://$BUCKET_NAME/$MODEL_NAME/GLUE/submission/AX.tsv\" \\\n",
        "  \"gs://$BUCKET_NAME/$MODEL_NAME/GLUE/submission/CoLA.tsv\" \\\n",
        "  \"gs://$BUCKET_NAME/$MODEL_NAME/GLUE/submission/MNLI-m.tsv\" \\\n",
        "  \"gs://$BUCKET_NAME/$MODEL_NAME/GLUE/submission/MNLI-mm.tsv\" \\\n",
        "  \"gs://$BUCKET_NAME/$MODEL_NAME/GLUE/submission/MRPC.tsv\" \\\n",
        "  \"gs://$BUCKET_NAME/$MODEL_NAME/GLUE/submission/QNLI.tsv\" \\\n",
        "  \"gs://$BUCKET_NAME/$MODEL_NAME/GLUE/submission/QQP.tsv\" \\\n",
        "  \"gs://$BUCKET_NAME/$MODEL_NAME/GLUE/submission/RTE.tsv\" \\\n",
        "  \"gs://$BUCKET_NAME/$MODEL_NAME/GLUE/submission/SST-2.tsv\" \\\n",
        "  \"gs://$BUCKET_NAME/$MODEL_NAME/GLUE/submission/STS-B.tsv\" \\\n",
        "  \"gs://$BUCKET_NAME/$MODEL_NAME/GLUE/submission/WNLI.tsv\" \\\n",
        "  submission/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUzhiM3X_TYY",
        "outputId": "057cd42a-c3c1-4721-e709-52b72322eff2"
      },
      "outputs": [],
      "source": [
        "!wc -l submission/*.tsv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6JIRfUsOBKiY"
      },
      "outputs": [],
      "source": [
        "#    1105 AX.tsv\n",
        "#    1064 CoLA.tsv\n",
        "#    9848 MNLI-mm.tsv\n",
        "#    9797 MNLI-m.tsv\n",
        "#    1726 MRPC.tsv\n",
        "#    5464 QNLI.tsv\n",
        "#  390966 QQP.tsv\n",
        "#    3001 RTE.tsv\n",
        "#    1822 SST-2.tsv\n",
        "#    1380 STS-B.tsv\n",
        "#     147 WNLI.tsv\n",
        "#  426597 total "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnXvB4WZACUf",
        "outputId": "bf1491fc-5b89-4961-8952-624f87e5c4f2"
      },
      "outputs": [],
      "source": [
        "!zip -r submission.zip submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPDtWBEtBXjY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
