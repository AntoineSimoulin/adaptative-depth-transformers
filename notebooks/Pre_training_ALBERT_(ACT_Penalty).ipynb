{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bhDgyCVEPRt"
      },
      "source": [
        "# Pre-training ALBERT from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApXpBWPFEHVk"
      },
      "source": [
        "## Set up environnement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3--WQpjeDl0b",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "%tensorflow_version 1.x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgjcjGS3DsVI",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "# import nltk\n",
        "import random\n",
        "import logging\n",
        "import tensorflow as tf\n",
        "\n",
        "# from glob import glob\n",
        "from google.colab import auth\n",
        "# from tensorflow.keras.utils import Progbar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJ8WIIemDsZT",
        "outputId": "3fea79d2-45dd-4e23-9161-72c976932b93",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "auth.authenticate_user()\n",
        "\n",
        "# configure logging\n",
        "log = logging.getLogger('tensorflow')\n",
        "log.setLevel(logging.INFO)\n",
        "\n",
        "# create formatter and add it to the handlers\n",
        "formatter = logging.Formatter('%(asctime)s :  %(message)s')\n",
        "sh = logging.StreamHandler()\n",
        "sh.setLevel(logging.INFO)\n",
        "sh.setFormatter(formatter)\n",
        "log.handlers = [sh]\n",
        "\n",
        "if 'COLAB_TPU_ADDR' in os.environ:\n",
        "  log.info(\"Using TPU runtime\")\n",
        "  USE_TPU = True\n",
        "  TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "\n",
        "  with tf.Session(TPU_ADDRESS) as session:\n",
        "    log.info('TPU address is ' + TPU_ADDRESS)\n",
        "    # Upload credentials to TPU.\n",
        "    with open('/content/adc.json', 'r') as f:\n",
        "      auth_info = json.load(f)\n",
        "    tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "    \n",
        "else:\n",
        "  log.warning('Not connected to TPU runtime')\n",
        "  USE_TPU = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMnmi3c7EWSe"
      },
      "source": [
        "## Import code and data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YphM7VGaxfoB",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "!pip -q install sentencepiece\n",
        "!test -d albert || git clone https://github.com/google-research/albert\n",
        "\n",
        "if not 'albert' in sys.path:\n",
        "  sys.path += ['albert']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQ6QZN_bDsXV",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import sentencepiece as spm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--Xa927nDsbd",
        "outputId": "e23838b8-0be2-45a5-f525-2840f164714c",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "#@title GCS configuration\n",
        "\n",
        "FROM_TF_HUB = False #@param {type:\"boolean\"}\n",
        "\n",
        "PROJECT_ID = '' #@param {type:\"string\"}\n",
        "os.environ['GOOGLE_CLOUD_PROJECT'] = PROJECT_ID\n",
        "\n",
        "!gcloud config set project $PROJECT_ID\n",
        "PRETRAINING_DIR = \"\" #@param {type:\"string\"}\n",
        "BUCKET_NAME = \"\" #@param {type:\"string\"}\n",
        "MODEL_DIR = \"\" #@param {type:\"string\"}\n",
        "tf.gfile.MkDir(MODEL_DIR)\n",
        "\n",
        "\n",
        "if not BUCKET_NAME:\n",
        "  log.warning(\"WARNING: BUCKET_NAME is not set. \"\n",
        "              \"You will not be able to train the model.\")\n",
        "\n",
        "if BUCKET_NAME:\n",
        "  BUCKET_PATH = \"gs://{}\".format(BUCKET_NAME)\n",
        "else:\n",
        "  BUCKET_PATH = \".\"\n",
        "\n",
        "BERT_GCS_DIR = \"{}/{}\".format(BUCKET_PATH, MODEL_DIR)\n",
        "DATA_GCS_DIR = \"{}/{}\".format(BUCKET_PATH, PRETRAINING_DIR)\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### TF hub model (fill if FROM_TF_HUB)\n",
        "\n",
        "if FROM_TF_HUB:\n",
        "  ALBERT_MODEL_HUB = 'https://tfhub.dev/google/albert_' + ALBERT_MODEL + '/' + VERSION\n",
        "  ALBERT_MODEL = 'base' #@param [\"base\", \"large\", \"xlarge\", \"xxlarge\"]\n",
        "  VERSION = \"1\" #@param [\"1\", \"2\", \"3\"]\n",
        "else:\n",
        "  ALBERT_MODEL_HUB = None\n",
        "  ALBERT_GCS_DIR = \"{}/{}\".format(BUCKET_PATH, MODEL_DIR)\n",
        "  DATA_GCS_DIR = \"{}/{}\".format(BUCKET_PATH, PRETRAINING_DIR)\n",
        "  ALBERT_CONFIG_FILE = os.path.join(ALBERT_GCS_DIR, \"albert_config.json\")\n",
        "\n",
        "if not FROM_TF_HUB and (not BUCKET_PATH or BUCKET_PATH == \"gs://\"):\n",
        "  raise ValueError(\"You must configure at least one of\"\n",
        "                   \"`TF_HUB` and `BUCKET_NAME`\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "fYlKhBRNp_Jx",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "#@title Vocabulary\n",
        "\n",
        "VOC_SIZE = 30000 #@param {type: \"integer\"}\n",
        "VOCAB_FILE = \"30k-clean-v2.vocab\" #@param {type:\"string\"}\n",
        "SPM_MODEL_FILE = \"30k-clean-v2.model\" #@param {type:\"string\"}\n",
        "DO_LOWER_CASE = True #@param {type:\"boolean\"}\n",
        "# DO_LOWER_CASE = \"True\" #@param {type:\"string\"}\n",
        "# DO_LOWER_CASE = bool(DO_LOWER_CASE)\n",
        "\n",
        "VOCAB_FILE = os.path.join(BERT_GCS_DIR, VOCAB_FILE)\n",
        "SPM_MODEL_FILE = os.path.join(BERT_GCS_DIR, SPM_MODEL_FILE)\n",
        "\n",
        "VOCAB_UPOS = \"deprel.conll.encoder\" #@param {type:\"string\"}\n",
        "VOCAB_DEPS = \"upos.conll.encoder\" #@param {type:\"string\"}\n",
        "\n",
        "!gsutil cp gs://$BUCKET_NAME/$MODEL_DIR/$VOCAB_UPOS . >nul 2>&1\n",
        "!gsutil cp gs://$BUCKET_NAME/$MODEL_DIR/$VOCAB_DEPS . >nul 2>&1\n",
        "\n",
        "VOCAB_UPOS = os.path.join('.', VOCAB_UPOS)\n",
        "VOCAB_DEPS = os.path.join('.', VOCAB_DEPS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EdEg5GpEwRk"
      },
      "source": [
        "## Create Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFi-7k2-Ji9H",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from albert import (\n",
        "    modeling, \n",
        "    optimization, \n",
        "    tokenization\n",
        ")\n",
        "from albert.run_pretraining import (\n",
        "    input_fn_builder,\n",
        "    model_fn_builder\n",
        ")\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.INFO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4-uqfqpDsdz",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "attention_probs_dropout_prob = 0 #@param  {type:\"number\"}\n",
        "hidden_act = 'gelu' #@param [\"gelu\", \"relu\", \"tanh\", \"sigmoid\", \"linear\"]\n",
        "hidden_dropout_prob = 0 #@param  {type:\"number\"}\n",
        "embedding_size = 128 #@param {type:\"integer\"}\n",
        "hidden_size = 768 #@param {type:\"integer\"}\n",
        "initializer_range = 0.02 #@param  {type:\"number\"}\n",
        "intermediate_size = 3072 #@param {type:\"integer\"}\n",
        "max_position_embeddings = 512 #@param {type:\"integer\"}\n",
        "num_attention_heads = 12 #@param {type:\"integer\"}\n",
        "num_hidden_layers =  12#@param {type:\"integer\"}\n",
        "\n",
        "albert_base_config = {\n",
        "  \"attention_probs_dropout_prob\": attention_probs_dropout_prob,\n",
        "  \"hidden_act\": hidden_act,\n",
        "  \"hidden_dropout_prob\": hidden_dropout_prob,\n",
        "  \"embedding_size\": embedding_size,\n",
        "  \"hidden_size\": hidden_size,\n",
        "  \"initializer_range\": initializer_range,\n",
        "  \"intermediate_size\": intermediate_size,\n",
        "  \"max_position_embeddings\": max_position_embeddings,\n",
        "  \"num_attention_heads\": num_attention_heads,\n",
        "  \"num_hidden_layers\": num_hidden_layers,\n",
        "  \"num_hidden_groups\": 1,\n",
        "  \"net_structure_type\": 0,\n",
        "  \"gap_size\": 0,\n",
        "  \"num_memory_blocks\": 0,\n",
        "  \"inner_group_num\": 1,\n",
        "  \"down_scale_factor\": 1,\n",
        "  \"type_vocab_size\": 2,\n",
        "  \"vocab_size\": VOC_SIZE\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_25fQKUKqFuw",
        "outputId": "820f0515-f08c-4c36-fbf7-13057f542598",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "if not FROM_TF_HUB:\n",
        "  tokenizer = tokenization.FullTokenizer(\n",
        "        vocab_file=VOCAB_FILE, \n",
        "        do_lower_case=DO_LOWER_CASE,\n",
        "        spm_model_file=SPM_MODEL_FILE)\n",
        "else:\n",
        "  tokenizer = fine_tuning_utils.create_vocab(\n",
        "        hub_module=ALBERT_MODEL_HUB)\n",
        "\n",
        "MASK_TOKEN_ID = tokenizer.vocab['[MASK]']\n",
        "CLS_TOKEN_ID = tokenizer.vocab['[CLS]']\n",
        "SEP_TOKEN_ID = tokenizer.vocab['[SEP]']\n",
        "print(\"MASK token ID is {}.\".format(MASK_TOKEN_ID))\n",
        "print(\"CLS token ID is {}.\".format(CLS_TOKEN_ID))\n",
        "print(\"SEP token ID is {}.\".format(SEP_TOKEN_ID))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJqsPCLbdhCs",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "with open(\"{}/albert_config.json\".format(MODEL_DIR), \"w\") as fo:\n",
        "  json.dump(albert_base_config, fo, indent=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xt9UOdXldo5A",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# !gsutil -m cp $MODEL_DIR/albert_config.json gs://$BUCKET_NAME/$MODEL_DIR/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyDfMUTyWlCy"
      },
      "source": [
        "## Training\n",
        "\n",
        "Part 1: Train the model on 90% of training steps using a sentence length of 128\n",
        "Part 2: Train the model on 10% of training steps using a sentence length of 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "W-elUG_H9-Na",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Input data pipeline config\n",
        "TRAIN_BATCH_SIZE_PHASE_1 = 64 #@param {type:\"integer\"}\n",
        "NUM_ACCUMULATION_STEPS_PHASE_1 =  64#@param {type:\"integer\"}\n",
        "MAX_SEQ_LENGTH_PHASE_1 = 128 #@param {type:\"integer\"}\n",
        "TRAIN_STEPS_PHASE_1 = 112500 #@param {type:\"integer\"}\n",
        "LEARNING_RATE_PHASE_1 = 0.00176 #@param {type:\"number\"}\n",
        "WARMUP_STEPS_PHASE_1 = 3125 #@param {type:\"integer\"}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "6yFpYWCO9_Zv",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "TRAIN_BATCH_SIZE_PHASE_2 = 128 #@param {type:\"integer\"}\n",
        "NUM_ACCUMULATION_STEPS_PHASE_2 = 32 #@param {type:\"integer\"}\n",
        "MAX_SEQ_LENGTH_PHASE_2 = 512 #@param {type:\"integer\"}\n",
        "TRAIN_STEPS_PHASE_2 = 12500 #@param {type:\"integer\"}\n",
        "LEARNING_RATE_PHASE_2 = 0.000275 #@param {type:\"number\"}\n",
        "WARMUP_STEPS_PHASE_2 = 312 #@param {type:\"integer\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "wY5XkNLBDsf7",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "TAU = 5e-4 #@param {type:\"number\"}\n",
        "# TAU = float(TAU)\n",
        "MAX_PREDICTIONS = 20 #@param {type:\"integer\"}\n",
        "EVAL_BATCH_SIZE = 64 #@param {type:\"integer\"}\n",
        "OPTIMIZER = \"lamb\" #@param [\"adamw\", \"lamb\"]\n",
        "SAVE_CHECKPOINTS_STEPS = 5000 #@param {type:\"integer\"}\n",
        "KEEP_CHECKPOINTS_MAX = 10  #@param {type: \"slider\", min: 1, max: 15, step: 1}\n",
        "NUM_TPU_CORES = 8 #@param {type:\"integer\"}\n",
        "POLY_POWER = 1.0  #@param {type:\"number\"}\n",
        "# POLY_POWER = float(POLY_POWER)\n",
        "ITERATIONS_PER_LOOP = 1000 #@param {type:\"integer\"}\n",
        "EVAL_EVERY_N_SECONDS = 3600 #@param {type:\"integer\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ik2hT3Hw9S2g",
        "outputId": "fc3a61ad-7c3d-40fc-8f87-f7921d2fa133",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "phase = 1\n",
        "\n",
        "if FROM_TF_HUB:\n",
        "  CONFIG_FILE = None\n",
        "else:\n",
        "  CONFIG_FILE = os.path.join(BERT_GCS_DIR, \"albert_config.json\")\n",
        "\n",
        "# Check which phase is running\n",
        "INIT_CHECKPOINT = tf.train.latest_checkpoint(\"{}/{}/phase_{}\".format(BUCKET_PATH, MODEL_DIR, str(phase)))\n",
        "\n",
        "if INIT_CHECKPOINT:\n",
        "  ckpt_reader = tf.train.NewCheckpointReader(INIT_CHECKPOINT)\n",
        "  global_step = ckpt_reader.get_tensor('global_step')\n",
        "  print('global step from phrase 1 in {:,}.'.format(global_step))\n",
        "  if global_step >= TRAIN_STEPS_PHASE_1:\n",
        "    phase = 2\n",
        "    INIT_CHECKPOINT_2 = tf.train.latest_checkpoint(\"{}/{}/phase_{}\".format(BUCKET_PATH, MODEL_DIR, \"2\"))\n",
        "    if INIT_CHECKPOINT_2:\n",
        "      print(\"loading latest checkpoint from phase 2.\")\n",
        "      INIT_CHECKPOINT = INIT_CHECKPOINT_2\n",
        "      ckpt_reader = tf.train.NewCheckpointReader(INIT_CHECKPOINT)\n",
        "      global_step = ckpt_reader.get_tensor('global_step')\n",
        "      print('global step from phrase 2 in {:,}.'.format(global_step))\n",
        "    else:\n",
        "      # else, this is the first checkpoint in phase 2\n",
        "      print(\"no checkpoint from phase 2 yet.\")\n",
        "  else:\n",
        "    print(\"max step not reached for phase 1 yet.\")\n",
        "    phase = 1\n",
        "else:\n",
        "  print(\"no checkpoint from phase 1 yet.\")\n",
        "  phase = 1\n",
        "\n",
        "print(\"Forcing phase 1.\")\n",
        "phase = 1\n",
        "\n",
        "\n",
        "if phase == 1:\n",
        "  TRAIN_BATCH_SIZE = TRAIN_BATCH_SIZE_PHASE_1\n",
        "  NUM_ACCUMULATION_STEPS = NUM_ACCUMULATION_STEPS_PHASE_1\n",
        "  MAX_SEQ_LENGTH = MAX_SEQ_LENGTH_PHASE_1\n",
        "  TRAIN_STEPS = TRAIN_STEPS_PHASE_1\n",
        "  LEARNING_RATE = LEARNING_RATE_PHASE_1\n",
        "  WARMUP_STEPS = WARMUP_STEPS_PHASE_1\n",
        "else:\n",
        "  TRAIN_BATCH_SIZE = TRAIN_BATCH_SIZE_PHASE_2\n",
        "  NUM_ACCUMULATION_STEPS = NUM_ACCUMULATION_STEPS_PHASE_2\n",
        "  MAX_SEQ_LENGTH = MAX_SEQ_LENGTH_PHASE_2\n",
        "  TRAIN_STEPS = TRAIN_STEPS_PHASE_2\n",
        "  LEARNING_RATE = LEARNING_RATE_PHASE_2\n",
        "  WARMUP_STEPS = WARMUP_STEPS_PHASE_2\n",
        "\n",
        "LEARNING_RATE = float(LEARNING_RATE)\n",
        "MODEL_DIR_CKPT = \"{}/{}/phase_{}\".format(BUCKET_PATH, MODEL_DIR, str(phase))\n",
        "log.info(\"Total train batch size \"\n",
        "         \"(train_batch_size * num_accumulation_steps): {:,}\"\\\n",
        "         .format(TRAIN_BATCH_SIZE * NUM_ACCUMULATION_STEPS))\n",
        "log.info(\"Total training steps \"\n",
        "         \"(train_steps / num_accumulation_steps): {:,}\"\\\n",
        "        .format(int(TRAIN_STEPS))) #  / NUM_ACCUMULATION_STEPS\n",
        "log.info(\"Using checkpoint: {}\".format(INIT_CHECKPOINT))\n",
        "log.info(\"Saving model to: {}\".format(MODEL_DIR_CKPT))\n",
        "albert_config = modeling.AlbertConfig.from_json_file(CONFIG_FILE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3TnvKh8U-mF",
        "outputId": "b3a9f323-ad16-42b0-a026-793cdcd1eff9",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "input_files = !gsutil ls $DATA_GCS_DIR/$MAX_SEQ_LENGTH/shard*\n",
        "dev_files = !gsutil ls $DATA_GCS_DIR/ptb/*.tfrecord\n",
        "\n",
        "log.info(\"For train, Using {} data shards from {}\".format(len(input_files), DATA_GCS_DIR+ \"/\" + str(MAX_SEQ_LENGTH)))\n",
        "\n",
        "train_input_files = input_files[:-1]\n",
        "eval_input_files = [input_files[-1]]\n",
        "# eval_input_files = []\n",
        "# eval_input_files.extend(dev_files)\n",
        "\n",
        "log.info(\"For dev, using {} data shards from {}\".format(len(eval_input_files), DATA_GCS_DIR+ \"/ptb\"))\n",
        "\n",
        "num_eval_examples = 0\n",
        "for f in eval_input_files:\n",
        "  n_f = sum(1 for _ in tf.python_io.tf_record_iterator(f))\n",
        "  print('{} contains {:,} examples'.format(f, n_f))\n",
        "  num_eval_examples += n_f\n",
        "print(\"Using {:,} dev examples\".format(num_eval_examples))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8GfCwA-DskZ",
        "outputId": "8110bf3e-d85c-41e7-896f-2744e25b0c97",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "model_fn = model_fn_builder(\n",
        "      albert_config=albert_config,\n",
        "      init_checkpoint=INIT_CHECKPOINT,\n",
        "      init_lr=LEARNING_RATE,\n",
        "      num_train_steps=TRAIN_STEPS,\n",
        "      num_warmup_steps=WARMUP_STEPS,\n",
        "      use_tpu=USE_TPU,\n",
        "      use_one_hot_embeddings=USE_TPU,\n",
        "      optimizer_name=OPTIMIZER,\n",
        "      poly_power=POLY_POWER,\n",
        "      start_warmup_step=0,\n",
        "      num_accumulation_steps=NUM_ACCUMULATION_STEPS,\n",
        "      model_dir=MODEL_DIR_CKPT,\n",
        "      tau=TAU,\n",
        "      vocab_upos=VOCAB_UPOS, \n",
        "      vocab_deps=VOCAB_DEPS, \n",
        "      mask_token_id=MASK_TOKEN_ID,\n",
        "      cls_token_id=CLS_TOKEN_ID,\n",
        "      sep_token_id=SEP_TOKEN_ID)\n",
        "\n",
        "tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)\n",
        "run_config = tf.contrib.tpu.RunConfig(\n",
        "    # cluster=tpu_cluster_resolver,\n",
        "    master=TPU_ADDRESS,\n",
        "    model_dir=MODEL_DIR_CKPT,\n",
        "    # log_step_count_steps=1000,\n",
        "    # save_summary_steps=1000,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,\n",
        "    keep_checkpoint_max=KEEP_CHECKPOINTS_MAX,\n",
        "    tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "        iterations_per_loop=ITERATIONS_PER_LOOP,\n",
        "        num_shards=NUM_TPU_CORES,\n",
        "        per_host_input_for_training=tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2))\n",
        "\n",
        "estimator = tf.contrib.tpu.TPUEstimator(\n",
        "    use_tpu=USE_TPU,\n",
        "    eval_on_tpu=False,\n",
        "    model_fn=model_fn,\n",
        "    config=run_config,\n",
        "    train_batch_size=TRAIN_BATCH_SIZE,\n",
        "    eval_batch_size=EVAL_BATCH_SIZE)\n",
        "\n",
        "train_input_fn = input_fn_builder(\n",
        "        input_files=input_files,\n",
        "        max_seq_length=MAX_SEQ_LENGTH,\n",
        "        max_predictions_per_seq=MAX_PREDICTIONS,\n",
        "        is_training=True)\n",
        "\n",
        "eval_input_fn = input_fn_builder(\n",
        "        input_files=eval_input_files,\n",
        "        max_seq_length=MAX_SEQ_LENGTH,\n",
        "        max_predictions_per_seq=MAX_PREDICTIONS,\n",
        "        is_training=False,\n",
        "        add_dep_and_pos=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y15IL43XnBzO",
        "outputId": "a8c2efd5-3c20-4394-fc8c-454f69107261",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "estimator.evaluate(input_fn=eval_input_fn, steps=int(num_eval_examples / EVAL_BATCH_SIZE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sz78dsjPZtQq",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPwBKHj8Dsmb",
        "outputId": "73065c69-6f70-42ee-c532-60cbce9bec0e",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# estimator.train(input_fn=train_input_fn, max_steps=TRAIN_STEPS)\n",
        "# setup train spec\n",
        "train_spec = tf.estimator.TrainSpec(\n",
        "    input_fn=train_input_fn,\n",
        "    max_steps=TRAIN_STEPS\n",
        "  )\n",
        "\n",
        "# setup eval spec evaluating ever n seconds\n",
        "eval_spec = tf.estimator.EvalSpec(\n",
        "    input_fn=eval_input_fn,\n",
        "    steps=int(num_eval_examples / EVAL_BATCH_SIZE),\n",
        "    throttle_secs=EVAL_EVERY_N_SECONDS)\n",
        "\n",
        "# run train and evaluate\n",
        "tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8X6TR4ckZ9X",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmoe3IQQDs6A",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwdoGRQHlwak",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmvzniuyDs8m",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jkxS1pTDs-n",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
